# -*- coding: utf-8 -*-
"""Fake and real news.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GbYZlZyN8FE3jVVjIJCvV5nMYTAgjtjy
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from gensim.models import KeyedVectors,Word2Vec

import warnings
warnings.filterwarnings("ignore")

df_true = pd.read_csv("/content/True.csv", error_bad_lines = False, engine = "python")

df_fake = pd.read_csv("/content/Fake.csv", error_bad_lines = False, engine = "python")

df_true.shape, df_fake.shape

df_true.isnull().sum()

df_fake.isnull().sum()

df_true.head()

df_true['subject'].value_counts()

df_fake['subject'].value_counts()

fig , axes = plt.subplots(1,2, figsize = (17,5))
sns.countplot(data=df_true, y='subject',ax = axes[0])
sns.countplot(data = df_fake,y = 'subject')
axes[0].set_title("True Data")
axes[1].set_title("Fake Data")
plt.tight_layout()
plt.show();

df_true["label"] = 0
df_fake["label"] = 1


df = pd.concat([df_true,df_fake], ignore_index = True)
df.head()

df.label.value_counts()

df['content'] = df['subject']+' '+df['title']
df.head()

df['content'][5]

df.drop(['title', 'text', 'subject', 'date'], axis = 1, inplace = True)

df.head()

!python -m spacy download en_core_web_lg

import spacy
nlp = spacy.load("en_core_web_lg")

def preprocess_vectorize(text):
    doc = nlp(text)

    filtered_token = []

    for token in doc:
        if not token.is_stop and not token.is_punct:
            filtered = token.lemma_
            filtered_token.append(filtered)

    return " ".join(filtered_token)

p =preprocess_vectorize('politicsNews White House, Congress prepare for talks on spending, immigration')
p

nlp(p).vector.shape

df['preprocessed_content'] = df['content'].apply(preprocess_vectorize)

df['preprocessed_content'][:5]

df['vectors'] = df['preprocessed_content'].apply(lambda text: nlp(text).vector)

df.head()

x = df['vectors']
y = df['label']

x= np.stack(x)

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

X = scaler.fit_transform(x)

from imblearn.over_sampling import SMOTE


smote=SMOTE(sampling_strategy='minority')
x_new,y_new=smote.fit_resample(X,y)

y_new.value_counts()

xtrain, xtest, ytrain, ytest = train_test_split(x_new, y_new, test_size=0.11, random_state = 0, stratify = y_new)

xtrain.shape

ytrain.value_counts()

ytest.value_counts()

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report

clf_MNB = MultinomialNB()

clf_MNB.fit(xtrain, ytrain)
ypred_MNB = clf_MNB.predict(xtest)

train_MNB =clf_MNB.score(xtrain, ytrain)
test_MNB =clf_MNB.score(xtest, ytest)
print(f'Train Acc: {train_MNB}\nTest Acc: {test_MNB}\n\nClassification Report:\n{classification_report(ytest, ypred_MNB)} ')

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

confusion_m =confusion_matrix(ytest, ypred_MNB)

sns.heatmap(confusion_m, annot = True, fmt = '.1f',
            xticklabels = ['True', 'Fake'],
            yticklabels = ['True', 'Fake'])
plt.xlabel('Predicted Output')
plt.ylabel('Actual Output')
plt.title("Confusion matrix for Multi_NB")
plt.show();

ytest[:5]

ypred_MNB[:5]

xtrain, xtest, ytrain, ytest = train_test_split(x_new, y_new, test_size=0.11, random_state = 0, stratify = y_new)

from sklearn.neighbors import KNeighborsClassifier

clf_kn = KNeighborsClassifier()

clf_kn.fit(xtrain, ytrain)
ypred_kn = clf_kn.predict(xtest)

train_kn =clf_kn.score(xtrain, ytrain)
test_kn =clf_kn.score(xtest, ytest)
print(f'Train Acc: {train_kn}\nTest Acc: {test_kn}\n\nClassification Report:\n{classification_report(ytest, ypred_kn)} ')

confusion_m =confusion_matrix(ytest, ypred_kn)

sns.heatmap(confusion_m, annot = True, fmt = '.1f',
            xticklabels = ['True', 'Fake'],
            yticklabels = ['True', 'Fake'])
plt.xlabel('Predicted Output')
plt.ylabel('Actual Output')
plt.title("Confusion matrix for  KNeighborsClassifier")
plt.show();

ypred_kn[:5]

ytest[:5]

df['preprocessed_content'][33494]

