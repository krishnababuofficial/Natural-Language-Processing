{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339ac3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_hub\n",
    "#!pip install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4069cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text         # Registers the ops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9e89ed",
   "metadata": {},
   "source": [
    "- for each of this encoder model url thier is corresponding preprocessor url, which the link is given in the end of the this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f7765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_url = \"https://kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3\"\n",
    "encoder_url = \"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-l-12-h-768-a-12/versions/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f3d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hub layer by passing the url\n",
    "\n",
    "bert_preprocess_model = hub.KerasLayer(preprocess_url)\n",
    "bert_encoder = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f013dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_word_ids', 'input_type_ids', 'input_mask'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's apply some statements and do preprocessing on those statements\n",
    "\n",
    "test_text = ['nice movie', 'i love reading books']   # Create (word or sentence)embedding for this statement \n",
    "\n",
    "text_preprocess = bert_preprocess_model(test_text) \n",
    "text_preprocess.keys()                                            # Text_Preprocess is gona be in dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888cec85",
   "metadata": {},
   "source": [
    "_It preproceed those 2 sentence and produced this 3 objects\n",
    "lets see the individual element in the dictionary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37ead4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocess['input_mask']\n",
    "\n",
    "# \"input_mask\": has value 1 at the position of all input tokens present before padding and value 0 for the padding tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f736c",
   "metadata": {},
   "source": [
    "1. The encoder_inputs are a dict of three int32 Tensors, all with shape [batch_size, seq_length], whose elements represent the batch of input sequences as follows:  \n",
    "  \n",
    "2. The shape is (2,128)[batch_size, seq_length] batchsize = 2 & seq_length = 128, why 2 because we have 2-sentence and 128 is  maximum length of the sentence, you can see it as 2 mask for 2 sentence  \n",
    "  \n",
    "3. The first sentence is 2 word but the mask as 4 word [1, 1, 1, 1], lets try to understand that.. \n",
    "    - the way the word works is it will always put a special token [CLS] in the beginning and to seperate 2 sentences it will put a special token [SEP]   \n",
    "  \n",
    ">\" [CLS] to indicate the beginning of the sentence, [SEP] to separate multiple sentences, and [PAD] to make each sentence have the same number of tokens \"  \n",
    "  \n",
    "So now if you count tokens   \n",
    "1. ==> [ CLS nice movie SEP ] ==> [ 1, 1, 1, 1 ] - (4_ones)\n",
    "2. ==> [ CLS i love reading books SEP ] ==> [ 1, 1, 1, 1, 1, 1 ] - (6_ones) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb83e174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocess['input_type_ids']\n",
    "\n",
    "# \"input_type_ids\": has the index of the input segment that gave rise to the input token at the respective position.\n",
    "# The first input segment (index 0) includes the start-of-sequence token and its end-of-segment token. \n",
    "# The second segment (index 1, if present) includes its end-of-segment token. Padding tokens get index 0 again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24950396",
   "metadata": {},
   "source": [
    "- input_type_ids are very useful for multiple sentenceses in 1 statement for ourcase it's not intresting everything will be in 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67915c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[ 101, 3835, 3185,  102,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [ 101, 1045, 2293, 3752, 2808,  102,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocess['input_word_ids']\n",
    "\n",
    "# \"input_word_ids\": has the token ids of the input sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac5c263",
   "metadata": {},
   "source": [
    "- The *word_id* for **CLS** it is fixed **101** and for **SEP** it is fixed **102**, between the 101 & 102 are the individual unique_id's for the word's and this could be id form the vocabulary.  \n",
    " **This is part of the preprocessing stage and in next stage is to create wordembedding and so_.on..**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86dc6e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sequence_output', 'encoder_outputs', 'default', 'pooled_output'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_result = bert_encoder(text_preprocess)            #supply text_preprocessing\n",
    "bert_result.keys()                                          # bert_result is gona be in dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e218c",
   "metadata": {},
   "source": [
    "- *The encoder's outputs are the **\"pooled_output\"** to represents each input sequence as a whole, and the **\"sequence_output\"** to represent each input token in context. Either of those can be used as input to further model building.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31ad27ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
       "array([[-0.82307994, -0.3302166 ,  0.05804183, ...,  0.15002297,\n",
       "        -0.5304849 ,  0.8495955 ],\n",
       "       [-0.85588014, -0.2829506 ,  0.00608959, ...,  0.15767564,\n",
       "        -0.62548584,  0.88712823]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_result['pooled_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daccb8ca",
   "metadata": {},
   "source": [
    "- \"pooled_output\": a float32 Tensor of shape [batch_size, dim] with the embedding of each input sequence as a whole, derived from sequence_output in some trainable manner.\n",
    "\n",
    "- It is embedding for the entier sentence\n",
    "- We know about the 2(shape) which is the 2 sentence. What is that 768 ..?\n",
    "     - 768 represents the **vector_size** (the embedding vector_size) the vector_size 768 accuratly represent the 2-statements in form of numbers, bert as generate meaningfull vector out of the statement.\n",
    "     - Now we can use this vector in nlp task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc16105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       "array([[[-0.04972755, -0.16134058, -0.04497375, ..., -0.19434923,\n",
       "          0.15166745,  0.07051349],\n",
       "        [ 0.40138048, -0.71619916,  0.7960523 , ..., -0.34071296,\n",
       "          0.01467817, -0.2820489 ],\n",
       "        [ 0.15850015, -0.13599618, -0.3122563 , ..., -0.311211  ,\n",
       "         -0.10993702, -0.5535933 ],\n",
       "        ...,\n",
       "        [-0.07264659, -0.22785553,  0.50889325, ..., -0.02908406,\n",
       "          0.10880314,  0.17614338],\n",
       "        [-0.35652003, -0.6121791 ,  0.10107114, ...,  0.15914942,\n",
       "          0.01639713, -0.17355037],\n",
       "        [-0.08667839, -0.28234947,  0.47228283, ...,  0.03270616,\n",
       "          0.1036502 ,  0.07469998]],\n",
       "\n",
       "       [[ 0.30540267,  0.21896993, -0.13581005, ..., -0.09990489,\n",
       "          0.18915819,  0.15679148],\n",
       "        [ 0.4269296 ,  0.14352971, -0.40460443, ..., -0.20114142,\n",
       "          0.7126101 , -0.12644345],\n",
       "        [ 1.0143212 ,  0.7115688 ,  0.28236336, ...,  0.23428604,\n",
       "          0.21727912, -0.2049999 ],\n",
       "        ...,\n",
       "        [ 0.37808043,  0.06616119,  0.34094408, ...,  0.38289186,\n",
       "         -0.02551693, -0.1713349 ],\n",
       "        [ 0.37210488,  0.06437553,  0.34066   , ...,  0.3784461 ,\n",
       "         -0.01585735, -0.14184359],\n",
       "        [ 0.29070684, -0.01170252,  0.40727815, ...,  0.3995425 ,\n",
       "         -0.00678592, -0.20485826]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_result['sequence_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5852ba",
   "metadata": {},
   "source": [
    "- **\"sequence_output\"**: a float32 Tensor of shape [batch_size, seq_length, dim] with the context-aware embedding of each token of every packed input sequence.\n",
    "1. it is a individual word embedding vector\n",
    "   - the size = 2, for 2 sentence for each senctence, each word 768 vector\n",
    "2. What is 128 ..?\n",
    "    - 128 is seq_length, for each sentence we have padding 128\n",
    "    - For each of this word their is 768 size vector\n",
    "    - for nice this is the vector [-0.04972755, -0.16134058, -0.04497375, ..., -0.19434923, 0.15166745,  0.07051349],\n",
    "    - movie [ 0.40138048, -0.71619916,  0.7960523 , ..., -0.34071296, 0.01467817, -0.2820489 ],\n",
    "    -  wait a minute, why the padding also have the number ..?\n",
    "           - Because it is contextualized embedding, the vector for padding will have context of the sentence[Contextual embeddings assign a vector to each \"token\".]\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c887d8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_result['encoder_outputs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae17c7",
   "metadata": {},
   "source": [
    "- if you the length of the encoder_outputs it is 12, the reason is 12 because we are using **BERT BASE VERSION**\n",
    "     - we have 12 encoder in each layer we have 768 size embedding vector\n",
    "- Encoder_outputs are output of each individual encoder which we have 12, and ech of them 12 if we look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11b2aee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       "array([[[ 0.1353064 ,  0.03766439, -0.06827549, ...,  0.04103095,\n",
       "          0.0873357 , -0.01989367],\n",
       "        [ 1.0477227 ,  1.0093771 ,  1.1757256 , ...,  0.51764846,\n",
       "         -0.01262756, -0.45692933],\n",
       "        [-0.06056276,  0.48112586, -0.07248963, ...,  0.6646982 ,\n",
       "          0.7341418 , -0.950563  ],\n",
       "        ...,\n",
       "        [-0.11729388, -0.24713397,  0.6668384 , ...,  0.5240912 ,\n",
       "         -0.07797258,  0.13272873],\n",
       "        [-0.21674249, -0.26885363,  0.5428592 , ...,  0.55586183,\n",
       "          0.00172372,  0.03732114],\n",
       "        [-0.10257089, -0.19211394,  0.5575123 , ...,  0.8435401 ,\n",
       "         -0.278187  , -0.02471282]],\n",
       "\n",
       "       [[ 0.22008246,  0.056191  , -0.07639271, ...,  0.04418512,\n",
       "          0.08938991,  0.04973042],\n",
       "        [ 0.5641079 ,  1.1693724 , -0.21900474, ...,  0.58388084,\n",
       "          0.69806415,  0.05612411],\n",
       "        [ 1.3346661 ,  0.7997389 ,  0.40960526, ...,  0.6379217 ,\n",
       "          0.8347206 , -0.14927903],\n",
       "        ...,\n",
       "        [ 0.05555841, -0.34511647,  0.65489256, ...,  0.20882279,\n",
       "         -0.29350373,  0.09280901],\n",
       "        [-0.01143286, -0.39375013,  0.52427405, ...,  0.25200582,\n",
       "         -0.1923655 , -0.00244053],\n",
       "        [ 0.11935128, -0.311395  ,  0.5589876 , ...,  0.5558872 ,\n",
       "         -0.5065892 , -0.08272179]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at 1st one\n",
    "\n",
    "bert_result['encoder_outputs'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66d465",
   "metadata": {},
   "source": [
    "- you know that (2, 128, 768), \n",
    "    1. **2** *because whe have 2 sentences*\n",
    "    2. **128** *because the statement as 128 words including the padding*\n",
    "    3. **768** *for each word it as 768 size embedding vector*\n",
    "    \n",
    "- the last layer if you see the 12th one    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a600a272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128, 768), dtype=bool, numpy=\n",
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_result['encoder_outputs'][11] == bert_result['sequence_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a3c0e0",
   "metadata": {},
   "source": [
    "- the 12th layer, i know i have typed 11 because it start from 0 that mean the 12th layer is 11\n",
    "- the 12th layer is same as your sequence output, if you compare that..they will be same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec555ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence):\n",
    "    preprocessed_text = bert_preprocess_model(sentence)\n",
    "    return bert_encoder(preprocessed_text)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64294229",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = get_sentence_embedding([\n",
    "    \n",
    "    # Fruits names\n",
    "    'apple', 'banana',\n",
    "    'grape', 'orange',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "978a8ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 768), dtype=float32, numpy=\n",
       "array([[-0.81964564, -0.29609612,  0.20951706, ...,  0.25593337,\n",
       "        -0.58743   ,  0.8434557 ],\n",
       "       [-0.760692  , -0.1421939 ,  0.49604598, ...,  0.42165306,\n",
       "        -0.53221405,  0.80312175],\n",
       "       [-0.854085  , -0.17408374,  0.23000933, ...,  0.22893815,\n",
       "        -0.5581087 ,  0.851655  ],\n",
       "       [-0.8363078 , -0.23830137,  0.3845352 , ...,  0.45564723,\n",
       "        -0.6078616 ,  0.82788914]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0889f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#cosine similarity is a way to measure how similar the two vectors are to each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94f03387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9659778]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([e[0]], [e[1]]) #Apple , Banana -- 96% similar  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef25fae",
   "metadata": {},
   "source": [
    ">- BERT Article: By **_Jay Alammar_** explained in visual way [BERT](https://jalammar.github.io/illustrated-bert/)  \n",
    "\n",
    ">- Bert & TensorFlow Hub link - [BERT](https://www.kaggle.com/models/tensorflow/bert/frameworks/tensorFlow2/variations/en-uncased-l-12-h-768-a-12), [TF_HUB](https://www.tensorflow.org/hub)  \n",
    "\n",
    ">- To learn about this bert en-uncased-Preprocessor. click - [PREPROCEESSOR](https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3)\n",
    "\n",
    ">- To learn about bert Model APIs - [MODEL API](https://www.tensorflow.org/hub/common_saved_model_apis/text#transformer-encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f9036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
